{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue  # for priority queue\n",
    "import copy # for deepcopy\n",
    "import random # for random.choice\n",
    "import pandas as pd # for dataframe\n",
    "import numpy as np # for numpy\n",
    "import math # for math.sqrt\n",
    "import copy # for deepcopy\n",
    "import time # for time.time()\n",
    "from sklearn.preprocessing import StandardScaler # for standardization\n",
    "class Node:\n",
    "    def __init__(self, state, parent, accuracy): # constructor\n",
    "        self.state = state # the current node(current feature sets) of the node\n",
    "        self.parent = parent # the parent node of current node\n",
    "        self.accuracy = accuracy # the accuracy of current node\n",
    "    def get_current_node(self): # return the current node\n",
    "        return self.state\n",
    "    def get_accuracy(self): # return the accuracy of current node\n",
    "        return self.accuracy\n",
    "    def __lt__(self, next): # this is for the priority queue\n",
    "        return self.accuracy < next.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.068837</td>\n",
       "      <td>3.140338</td>\n",
       "      <td>1.289108</td>\n",
       "      <td>0.576342</td>\n",
       "      <td>2.726862</td>\n",
       "      <td>1.910392</td>\n",
       "      <td>4.602715</td>\n",
       "      <td>3.362192</td>\n",
       "      <td>4.025317</td>\n",
       "      <td>2.850399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.542659</td>\n",
       "      <td>2.585977</td>\n",
       "      <td>4.160459</td>\n",
       "      <td>3.454206</td>\n",
       "      <td>4.443695</td>\n",
       "      <td>4.023849</td>\n",
       "      <td>3.198773</td>\n",
       "      <td>2.973449</td>\n",
       "      <td>2.617771</td>\n",
       "      <td>1.695701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.036878</td>\n",
       "      <td>4.126735</td>\n",
       "      <td>1.568875</td>\n",
       "      <td>2.820503</td>\n",
       "      <td>4.084704</td>\n",
       "      <td>1.546575</td>\n",
       "      <td>2.765708</td>\n",
       "      <td>4.137490</td>\n",
       "      <td>2.395914</td>\n",
       "      <td>4.142082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2         3         4         5         6         7   \\\n",
       "0  2.0  5.068837  3.140338  1.289108  0.576342  2.726862  1.910392  4.602715   \n",
       "1  2.0  4.542659  2.585977  4.160459  3.454206  4.443695  4.023849  3.198773   \n",
       "2  2.0  3.036878  4.126735  1.568875  2.820503  4.084704  1.546575  2.765708   \n",
       "\n",
       "         8         9         10  \n",
       "0  3.362192  4.025317  2.850399  \n",
       "1  2.973449  2.617771  1.695701  \n",
       "2  4.137490  2.395914  4.142082  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data \n",
    "small_test_file_name = \"small-test-dataset.txt\"\n",
    "small_test = pd.read_csv(small_test_file_name, delimiter=r\"\\s+\", header = None)\n",
    "small_test.head(3) # print the first 3 rows\n",
    "#small_test[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.522975</td>\n",
       "      <td>1.104877</td>\n",
       "      <td>3.628799</td>\n",
       "      <td>2.147955</td>\n",
       "      <td>3.915596</td>\n",
       "      <td>4.518589</td>\n",
       "      <td>3.506553</td>\n",
       "      <td>3.071337</td>\n",
       "      <td>3.844453</td>\n",
       "      <td>...</td>\n",
       "      <td>4.426448</td>\n",
       "      <td>2.654279</td>\n",
       "      <td>3.375515</td>\n",
       "      <td>3.081816</td>\n",
       "      <td>3.126470</td>\n",
       "      <td>3.918826</td>\n",
       "      <td>4.311717</td>\n",
       "      <td>1.755977</td>\n",
       "      <td>2.727675</td>\n",
       "      <td>3.088761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.090355</td>\n",
       "      <td>1.078130</td>\n",
       "      <td>2.933345</td>\n",
       "      <td>2.337623</td>\n",
       "      <td>2.808290</td>\n",
       "      <td>3.261811</td>\n",
       "      <td>3.062445</td>\n",
       "      <td>3.763595</td>\n",
       "      <td>3.034178</td>\n",
       "      <td>...</td>\n",
       "      <td>2.916443</td>\n",
       "      <td>2.685065</td>\n",
       "      <td>3.151358</td>\n",
       "      <td>2.183804</td>\n",
       "      <td>2.447051</td>\n",
       "      <td>1.924592</td>\n",
       "      <td>3.487203</td>\n",
       "      <td>1.479864</td>\n",
       "      <td>3.268112</td>\n",
       "      <td>3.568360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.380721</td>\n",
       "      <td>3.581257</td>\n",
       "      <td>2.643476</td>\n",
       "      <td>2.725065</td>\n",
       "      <td>2.147616</td>\n",
       "      <td>1.914770</td>\n",
       "      <td>3.964033</td>\n",
       "      <td>5.826476</td>\n",
       "      <td>2.368161</td>\n",
       "      <td>...</td>\n",
       "      <td>1.282696</td>\n",
       "      <td>2.814488</td>\n",
       "      <td>3.241585</td>\n",
       "      <td>4.250583</td>\n",
       "      <td>3.309664</td>\n",
       "      <td>3.373909</td>\n",
       "      <td>4.880085</td>\n",
       "      <td>3.606023</td>\n",
       "      <td>3.558190</td>\n",
       "      <td>4.547852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2         3         4         5         6         7   \\\n",
       "0  2.0  2.522975  1.104877  3.628799  2.147955  3.915596  4.518589  3.506553   \n",
       "1  2.0  3.090355  1.078130  2.933345  2.337623  2.808290  3.261811  3.062445   \n",
       "2  2.0  3.380721  3.581257  2.643476  2.725065  2.147616  1.914770  3.964033   \n",
       "\n",
       "         8         9   ...        31        32        33        34        35  \\\n",
       "0  3.071337  3.844453  ...  4.426448  2.654279  3.375515  3.081816  3.126470   \n",
       "1  3.763595  3.034178  ...  2.916443  2.685065  3.151358  2.183804  2.447051   \n",
       "2  5.826476  2.368161  ...  1.282696  2.814488  3.241585  4.250583  3.309664   \n",
       "\n",
       "         36        37        38        39        40  \n",
       "0  3.918826  4.311717  1.755977  2.727675  3.088761  \n",
       "1  1.924592  3.487203  1.479864  3.268112  3.568360  \n",
       "2  3.373909  4.880085  3.606023  3.558190  4.547852  \n",
       "\n",
       "[3 rows x 41 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "large_test_file_name = \"Large-test-dataset.txt\"\n",
    "large_test = pd.read_csv(large_test_file_name, delimiter=r\"\\s+\", header = None) #\n",
    "large_test.head(3) # print the first 3 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.176932</td>\n",
       "      <td>0.242524</td>\n",
       "      <td>-1.534037</td>\n",
       "      <td>-2.348508</td>\n",
       "      <td>-0.329525</td>\n",
       "      <td>-0.987070</td>\n",
       "      <td>1.540914</td>\n",
       "      <td>0.352003</td>\n",
       "      <td>1.162366</td>\n",
       "      <td>0.133282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.635395</td>\n",
       "      <td>-0.275870</td>\n",
       "      <td>1.148029</td>\n",
       "      <td>0.521261</td>\n",
       "      <td>1.333220</td>\n",
       "      <td>1.120200</td>\n",
       "      <td>0.071603</td>\n",
       "      <td>-0.057058</td>\n",
       "      <td>-0.173787</td>\n",
       "      <td>-1.071278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.085661</td>\n",
       "      <td>1.164924</td>\n",
       "      <td>-1.272713</td>\n",
       "      <td>-0.110660</td>\n",
       "      <td>0.985538</td>\n",
       "      <td>-1.349822</td>\n",
       "      <td>-0.381626</td>\n",
       "      <td>1.167823</td>\n",
       "      <td>-0.384391</td>\n",
       "      <td>1.480742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         0         1         2         3         4         5         6  \\\n",
       "0  2.0  2.176932  0.242524 -1.534037 -2.348508 -0.329525 -0.987070  1.540914   \n",
       "1  2.0  1.635395 -0.275870  1.148029  0.521261  1.333220  1.120200  0.071603   \n",
       "2  2.0  0.085661  1.164924 -1.272713 -0.110660  0.985538 -1.349822 -0.381626   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.352003  1.162366  0.133282  \n",
       "1 -0.057058 -0.173787 -1.071278  \n",
       "2  1.167823 -0.384391  1.480742  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is for the normalize small dataset\n",
    "#small_test.iloc[:,1:small_test.shape[1]] # columns 1 to the end\n",
    "scaler = StandardScaler() # standard scaler\n",
    "small_test_scaled = scaler.fit_transform(small_test.iloc[:,1:small_test.shape[1]]) # fit and transform the data\n",
    "small_test_scaled = pd.DataFrame(small_test_scaled) # convert to dataframe\n",
    "small_test_normalized = pd.concat([small_test.iloc[:,0:1], small_test_scaled], axis=1) # concatenate the data\n",
    "small_test_normalized.head(3) # print the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.503664</td>\n",
       "      <td>-1.895417</td>\n",
       "      <td>0.625103</td>\n",
       "      <td>-0.852914</td>\n",
       "      <td>0.861414</td>\n",
       "      <td>1.455623</td>\n",
       "      <td>0.569991</td>\n",
       "      <td>0.076615</td>\n",
       "      <td>0.860083</td>\n",
       "      <td>...</td>\n",
       "      <td>1.415823</td>\n",
       "      <td>-0.311344</td>\n",
       "      <td>0.388363</td>\n",
       "      <td>0.033654</td>\n",
       "      <td>0.153260</td>\n",
       "      <td>0.906036</td>\n",
       "      <td>1.325886</td>\n",
       "      <td>-1.269118</td>\n",
       "      <td>-0.278237</td>\n",
       "      <td>0.109275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.088848</td>\n",
       "      <td>-1.922914</td>\n",
       "      <td>-0.037149</td>\n",
       "      <td>-0.661111</td>\n",
       "      <td>-0.239240</td>\n",
       "      <td>0.240815</td>\n",
       "      <td>0.110253</td>\n",
       "      <td>0.773468</td>\n",
       "      <td>0.051927</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051202</td>\n",
       "      <td>-0.279882</td>\n",
       "      <td>0.160744</td>\n",
       "      <td>-0.843274</td>\n",
       "      <td>-0.514320</td>\n",
       "      <td>-1.061404</td>\n",
       "      <td>0.487239</td>\n",
       "      <td>-1.542670</td>\n",
       "      <td>0.267849</td>\n",
       "      <td>0.603503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.392077</td>\n",
       "      <td>0.650387</td>\n",
       "      <td>-0.313181</td>\n",
       "      <td>-0.269305</td>\n",
       "      <td>-0.895945</td>\n",
       "      <td>-1.061241</td>\n",
       "      <td>1.043570</td>\n",
       "      <td>2.850043</td>\n",
       "      <td>-0.612348</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.638447</td>\n",
       "      <td>-0.147614</td>\n",
       "      <td>0.252365</td>\n",
       "      <td>1.174979</td>\n",
       "      <td>0.333262</td>\n",
       "      <td>0.368440</td>\n",
       "      <td>1.903996</td>\n",
       "      <td>0.563762</td>\n",
       "      <td>0.560959</td>\n",
       "      <td>1.612868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         0         1         2         3         4         5         6   \\\n",
       "0  2.0 -0.503664 -1.895417  0.625103 -0.852914  0.861414  1.455623  0.569991   \n",
       "1  2.0  0.088848 -1.922914 -0.037149 -0.661111 -0.239240  0.240815  0.110253   \n",
       "2  2.0  0.392077  0.650387 -0.313181 -0.269305 -0.895945 -1.061241  1.043570   \n",
       "\n",
       "         7         8   ...        30        31        32        33        34  \\\n",
       "0  0.076615  0.860083  ...  1.415823 -0.311344  0.388363  0.033654  0.153260   \n",
       "1  0.773468  0.051927  ... -0.051202 -0.279882  0.160744 -0.843274 -0.514320   \n",
       "2  2.850043 -0.612348  ... -1.638447 -0.147614  0.252365  1.174979  0.333262   \n",
       "\n",
       "         35        36        37        38        39  \n",
       "0  0.906036  1.325886 -1.269118 -0.278237  0.109275  \n",
       "1 -1.061404  0.487239 -1.542670  0.267849  0.603503  \n",
       "2  0.368440  1.903996  0.563762  0.560959  1.612868  \n",
       "\n",
       "[3 rows x 41 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is for the normalize large dataset\n",
    "large_test_scaled = scaler.fit_transform(large_test.iloc[:,1:large_test.shape[1]]) # fit and transform the data\n",
    "large_test_scaled = pd.DataFrame(large_test_scaled) # convert to dataframe\n",
    "large_test_normalized = pd.concat([large_test.iloc[:,0:1], large_test_scaled], axis=1) # concatenate the data\n",
    "large_test_normalized.head(3) # print the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.588139</td>\n",
       "      <td>-1.759326</td>\n",
       "      <td>2.091809</td>\n",
       "      <td>-0.685387</td>\n",
       "      <td>1.727602</td>\n",
       "      <td>-0.362451</td>\n",
       "      <td>-0.043195</td>\n",
       "      <td>-0.667683</td>\n",
       "      <td>0.269320</td>\n",
       "      <td>-0.614092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.795138</td>\n",
       "      <td>-0.435755</td>\n",
       "      <td>-0.138534</td>\n",
       "      <td>-1.984583</td>\n",
       "      <td>1.131287</td>\n",
       "      <td>0.785214</td>\n",
       "      <td>0.337882</td>\n",
       "      <td>-0.263521</td>\n",
       "      <td>-0.793444</td>\n",
       "      <td>-1.895482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.330980</td>\n",
       "      <td>0.158997</td>\n",
       "      <td>0.211084</td>\n",
       "      <td>-1.277718</td>\n",
       "      <td>0.379159</td>\n",
       "      <td>-0.067180</td>\n",
       "      <td>-0.078171</td>\n",
       "      <td>1.917266</td>\n",
       "      <td>1.803082</td>\n",
       "      <td>-0.236975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2         3         4         5         6         7   \\\n",
       "0  1.0  0.588139 -1.759326  2.091809 -0.685387  1.727602 -0.362451 -0.043195   \n",
       "1  2.0 -1.795138 -0.435755 -0.138534 -1.984583  1.131287  0.785214  0.337882   \n",
       "2  2.0 -1.330980  0.158997  0.211084 -1.277718  0.379159 -0.067180 -0.078171   \n",
       "\n",
       "         8         9         10  \n",
       "0 -0.667683  0.269320 -0.614092  \n",
       "1 -0.263521 -0.793444 -1.895482  \n",
       "2  1.917266  1.803082 -0.236975  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data \n",
    "personal_small_test_file_name = \"CS170_Spring_2022_Small_data__102.txt\"\n",
    "personal_small_test = pd.read_csv(personal_small_test_file_name, delimiter=r\"\\s+\", header = None)\n",
    "personal_small_test.head(3) # print the first 3 rows\n",
    "#small_test[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.405550</td>\n",
       "      <td>-1.948408</td>\n",
       "      <td>-0.836609</td>\n",
       "      <td>-1.665288</td>\n",
       "      <td>-0.571342</td>\n",
       "      <td>-0.767871</td>\n",
       "      <td>0.248300</td>\n",
       "      <td>-0.302739</td>\n",
       "      <td>1.546041</td>\n",
       "      <td>...</td>\n",
       "      <td>1.199606</td>\n",
       "      <td>0.787637</td>\n",
       "      <td>-0.094080</td>\n",
       "      <td>-0.112492</td>\n",
       "      <td>-0.111032</td>\n",
       "      <td>0.055719</td>\n",
       "      <td>-0.168792</td>\n",
       "      <td>-0.310380</td>\n",
       "      <td>0.818675</td>\n",
       "      <td>0.613251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.577320</td>\n",
       "      <td>0.418193</td>\n",
       "      <td>2.043754</td>\n",
       "      <td>0.675542</td>\n",
       "      <td>-1.027219</td>\n",
       "      <td>-0.817929</td>\n",
       "      <td>1.977267</td>\n",
       "      <td>-0.855001</td>\n",
       "      <td>-0.941871</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.444444</td>\n",
       "      <td>-1.866266</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.767863</td>\n",
       "      <td>-0.489662</td>\n",
       "      <td>0.486264</td>\n",
       "      <td>0.628048</td>\n",
       "      <td>-1.644813</td>\n",
       "      <td>-0.803058</td>\n",
       "      <td>-0.282310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.428912</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>-1.660865</td>\n",
       "      <td>0.017425</td>\n",
       "      <td>0.483600</td>\n",
       "      <td>0.199327</td>\n",
       "      <td>-0.891506</td>\n",
       "      <td>-1.447127</td>\n",
       "      <td>-1.246280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.376826</td>\n",
       "      <td>-1.097380</td>\n",
       "      <td>-0.966164</td>\n",
       "      <td>-0.550853</td>\n",
       "      <td>0.440829</td>\n",
       "      <td>-1.568145</td>\n",
       "      <td>-0.647595</td>\n",
       "      <td>-0.616936</td>\n",
       "      <td>0.038132</td>\n",
       "      <td>0.733896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2         3         4         5         6         7   \\\n",
       "0  2.0 -0.405550 -1.948408 -0.836609 -1.665288 -0.571342 -0.767871  0.248300   \n",
       "1  2.0  2.577320  0.418193  2.043754  0.675542 -1.027219 -0.817929  1.977267   \n",
       "2  2.0  0.428912  0.004134 -1.660865  0.017425  0.483600  0.199327 -0.891506   \n",
       "\n",
       "         8         9   ...        31        32        33        34        35  \\\n",
       "0 -0.302739  1.546041  ...  1.199606  0.787637 -0.094080 -0.112492 -0.111032   \n",
       "1 -0.855001 -0.941871  ... -1.444444 -1.866266  0.841270  0.767863 -0.489662   \n",
       "2 -1.447127 -1.246280  ...  0.376826 -1.097380 -0.966164 -0.550853  0.440829   \n",
       "\n",
       "         36        37        38        39        40  \n",
       "0  0.055719 -0.168792 -0.310380  0.818675  0.613251  \n",
       "1  0.486264  0.628048 -1.644813 -0.803058 -0.282310  \n",
       "2 -1.568145 -0.647595 -0.616936  0.038132  0.733896  \n",
       "\n",
       "[3 rows x 41 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "personal_large_test_file_name = \"CS170_Spring_2022_Large_data__102.txt\"\n",
    "personal_large_test = pd.read_csv(personal_large_test_file_name, delimiter=r\"\\s+\", header = None) #\n",
    "personal_large_test.head(3) # print the first 3 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.445446</td>\n",
       "      <td>-1.705547</td>\n",
       "      <td>2.234270</td>\n",
       "      <td>-0.696021</td>\n",
       "      <td>1.750165</td>\n",
       "      <td>-0.268269</td>\n",
       "      <td>-0.066995</td>\n",
       "      <td>-0.818550</td>\n",
       "      <td>0.424966</td>\n",
       "      <td>-0.704246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.029604</td>\n",
       "      <td>-0.483656</td>\n",
       "      <td>-0.121353</td>\n",
       "      <td>-1.951128</td>\n",
       "      <td>1.142371</td>\n",
       "      <td>0.809770</td>\n",
       "      <td>0.320508</td>\n",
       "      <td>-0.418976</td>\n",
       "      <td>-0.767782</td>\n",
       "      <td>-2.025829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.547573</td>\n",
       "      <td>0.065406</td>\n",
       "      <td>0.247903</td>\n",
       "      <td>-1.268251</td>\n",
       "      <td>0.375765</td>\n",
       "      <td>0.009089</td>\n",
       "      <td>-0.102562</td>\n",
       "      <td>1.737053</td>\n",
       "      <td>2.146319</td>\n",
       "      <td>-0.315301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         0         1         2         3         4         5         6  \\\n",
       "0  1.0  0.445446 -1.705547  2.234270 -0.696021  1.750165 -0.268269 -0.066995   \n",
       "1  2.0 -2.029604 -0.483656 -0.121353 -1.951128  1.142371  0.809770  0.320508   \n",
       "2  2.0 -1.547573  0.065406  0.247903 -1.268251  0.375765  0.009089 -0.102562   \n",
       "\n",
       "          7         8         9  \n",
       "0 -0.818550  0.424966 -0.704246  \n",
       "1 -0.418976 -0.767782 -2.025829  \n",
       "2  1.737053  2.146319 -0.315301  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is for the normalize small dataset\n",
    "#small_test.iloc[:,1:small_test.shape[1]] # columns 1 to the end\n",
    "scaler = StandardScaler() # standard scaler\n",
    "personal_small_test_scaled = scaler.fit_transform(personal_small_test.iloc[:,1:personal_small_test.shape[1]]) # fit and transform the data\n",
    "personal_small_test_scaled = pd.DataFrame(personal_small_test_scaled) # convert to dataframe\n",
    "personal_small_test_normalized = pd.concat([personal_small_test.iloc[:,0:1], personal_small_test_scaled], axis=1) # concatenate the data\n",
    "personal_small_test_normalized.head(3) # print the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.391770</td>\n",
       "      <td>-1.928418</td>\n",
       "      <td>-0.859375</td>\n",
       "      <td>-1.779998</td>\n",
       "      <td>-0.581505</td>\n",
       "      <td>-0.852308</td>\n",
       "      <td>0.317156</td>\n",
       "      <td>-0.362693</td>\n",
       "      <td>1.534916</td>\n",
       "      <td>...</td>\n",
       "      <td>1.188706</td>\n",
       "      <td>0.812225</td>\n",
       "      <td>-0.064519</td>\n",
       "      <td>-0.116401</td>\n",
       "      <td>-0.088852</td>\n",
       "      <td>0.095598</td>\n",
       "      <td>-0.182002</td>\n",
       "      <td>-0.297991</td>\n",
       "      <td>0.815344</td>\n",
       "      <td>0.592579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.597055</td>\n",
       "      <td>0.395019</td>\n",
       "      <td>2.085808</td>\n",
       "      <td>0.626203</td>\n",
       "      <td>-1.041533</td>\n",
       "      <td>-0.902462</td>\n",
       "      <td>2.009165</td>\n",
       "      <td>-0.929342</td>\n",
       "      <td>-0.977328</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.466267</td>\n",
       "      <td>-1.806730</td>\n",
       "      <td>0.855671</td>\n",
       "      <td>0.769858</td>\n",
       "      <td>-0.466927</td>\n",
       "      <td>0.537229</td>\n",
       "      <td>0.620425</td>\n",
       "      <td>-1.636473</td>\n",
       "      <td>-0.805040</td>\n",
       "      <td>-0.296501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.444358</td>\n",
       "      <td>-0.011488</td>\n",
       "      <td>-1.702181</td>\n",
       "      <td>-0.050294</td>\n",
       "      <td>0.483042</td>\n",
       "      <td>0.116750</td>\n",
       "      <td>-0.798286</td>\n",
       "      <td>-1.536895</td>\n",
       "      <td>-1.284715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.362527</td>\n",
       "      <td>-1.047970</td>\n",
       "      <td>-0.922468</td>\n",
       "      <td>-0.557703</td>\n",
       "      <td>0.462198</td>\n",
       "      <td>-1.570078</td>\n",
       "      <td>-0.664163</td>\n",
       "      <td>-0.605477</td>\n",
       "      <td>0.035449</td>\n",
       "      <td>0.712351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         0         1         2         3         4         5         6   \\\n",
       "0  2.0 -0.391770 -1.928418 -0.859375 -1.779998 -0.581505 -0.852308  0.317156   \n",
       "1  2.0  2.597055  0.395019  2.085808  0.626203 -1.041533 -0.902462  2.009165   \n",
       "2  2.0  0.444358 -0.011488 -1.702181 -0.050294  0.483042  0.116750 -0.798286   \n",
       "\n",
       "         7         8   ...        30        31        32        33        34  \\\n",
       "0 -0.362693  1.534916  ...  1.188706  0.812225 -0.064519 -0.116401 -0.088852   \n",
       "1 -0.929342 -0.977328  ... -1.466267 -1.806730  0.855671  0.769858 -0.466927   \n",
       "2 -1.536895 -1.284715  ...  0.362527 -1.047970 -0.922468 -0.557703  0.462198   \n",
       "\n",
       "         35        36        37        38        39  \n",
       "0  0.095598 -0.182002 -0.297991  0.815344  0.592579  \n",
       "1  0.537229  0.620425 -1.636473 -0.805040 -0.296501  \n",
       "2 -1.570078 -0.664163 -0.605477  0.035449  0.712351  \n",
       "\n",
       "[3 rows x 41 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is for the normalize large dataset\n",
    "personal_large_test_scaled = scaler.fit_transform(personal_large_test.iloc[:,1:personal_large_test.shape[1]]) # fit and transform the data\n",
    "personal_large_test_scaled = pd.DataFrame(personal_large_test_scaled) # convert to dataframe\n",
    "personal_large_test_normalized = pd.concat([personal_large_test.iloc[:,0:1], personal_large_test_scaled], axis=1) # concatenate the data\n",
    "personal_large_test_normalized.head(3) # print the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.443213</td>\n",
       "      <td>-1.696998</td>\n",
       "      <td>2.223071</td>\n",
       "      <td>-0.692532</td>\n",
       "      <td>1.741392</td>\n",
       "      <td>-0.266924</td>\n",
       "      <td>-0.066659</td>\n",
       "      <td>-0.814447</td>\n",
       "      <td>0.422836</td>\n",
       "      <td>-0.700716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.019431</td>\n",
       "      <td>-0.481232</td>\n",
       "      <td>-0.120745</td>\n",
       "      <td>-1.941347</td>\n",
       "      <td>1.136645</td>\n",
       "      <td>0.805711</td>\n",
       "      <td>0.318901</td>\n",
       "      <td>-0.416876</td>\n",
       "      <td>-0.763934</td>\n",
       "      <td>-2.015675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.539815</td>\n",
       "      <td>0.065078</td>\n",
       "      <td>0.246660</td>\n",
       "      <td>-1.261893</td>\n",
       "      <td>0.373881</td>\n",
       "      <td>0.009043</td>\n",
       "      <td>-0.102047</td>\n",
       "      <td>1.728346</td>\n",
       "      <td>2.135560</td>\n",
       "      <td>-0.313720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2         3         4         5         6         7   \\\n",
       "0  1.0  0.443213 -1.696998  2.223071 -0.692532  1.741392 -0.266924 -0.066659   \n",
       "1  2.0 -2.019431 -0.481232 -0.120745 -1.941347  1.136645  0.805711  0.318901   \n",
       "2  2.0 -1.539815  0.065078  0.246660 -1.261893  0.373881  0.009043 -0.102047   \n",
       "\n",
       "         8         9         10  \n",
       "0 -0.814447  0.422836 -0.700716  \n",
       "1 -0.416876 -0.763934 -2.015675  \n",
       "2  1.728346  2.135560 -0.313720  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HOW TO NORMALIZE THE DATA \n",
    "# https://stackoverflow.com/questions/26414913/normalize-columns-of-pandas-data-frame\n",
    "df = personal_small_test.iloc[:,1:personal_small_test.shape[1]]\n",
    "normalized_df=(df-df.mean())/df.std()\n",
    "normalized_df.head(3)\n",
    "personal_small_test_normalized1 = pd.concat([personal_small_test.iloc[:,0:1], normalized_df], axis=1) # concatenate the data\n",
    "personal_small_test_normalized1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.391574</td>\n",
       "      <td>-1.927454</td>\n",
       "      <td>-0.858946</td>\n",
       "      <td>-1.779108</td>\n",
       "      <td>-0.581214</td>\n",
       "      <td>-0.851881</td>\n",
       "      <td>0.316997</td>\n",
       "      <td>-0.362512</td>\n",
       "      <td>1.534148</td>\n",
       "      <td>...</td>\n",
       "      <td>1.188112</td>\n",
       "      <td>0.811818</td>\n",
       "      <td>-0.064487</td>\n",
       "      <td>-0.116343</td>\n",
       "      <td>-0.088808</td>\n",
       "      <td>0.095551</td>\n",
       "      <td>-0.181911</td>\n",
       "      <td>-0.297841</td>\n",
       "      <td>0.814936</td>\n",
       "      <td>0.592282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.595757</td>\n",
       "      <td>0.394821</td>\n",
       "      <td>2.084765</td>\n",
       "      <td>0.625890</td>\n",
       "      <td>-1.041012</td>\n",
       "      <td>-0.902011</td>\n",
       "      <td>2.008160</td>\n",
       "      <td>-0.928877</td>\n",
       "      <td>-0.976840</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.465534</td>\n",
       "      <td>-1.805827</td>\n",
       "      <td>0.855243</td>\n",
       "      <td>0.769473</td>\n",
       "      <td>-0.466694</td>\n",
       "      <td>0.536960</td>\n",
       "      <td>0.620115</td>\n",
       "      <td>-1.635655</td>\n",
       "      <td>-0.804637</td>\n",
       "      <td>-0.296353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.444136</td>\n",
       "      <td>-0.011482</td>\n",
       "      <td>-1.701330</td>\n",
       "      <td>-0.050268</td>\n",
       "      <td>0.482801</td>\n",
       "      <td>0.116691</td>\n",
       "      <td>-0.797887</td>\n",
       "      <td>-1.536126</td>\n",
       "      <td>-1.284072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.362346</td>\n",
       "      <td>-1.047446</td>\n",
       "      <td>-0.922007</td>\n",
       "      <td>-0.557424</td>\n",
       "      <td>0.461967</td>\n",
       "      <td>-1.569292</td>\n",
       "      <td>-0.663831</td>\n",
       "      <td>-0.605174</td>\n",
       "      <td>0.035432</td>\n",
       "      <td>0.711995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2         3         4         5         6         7   \\\n",
       "0  2.0 -0.391574 -1.927454 -0.858946 -1.779108 -0.581214 -0.851881  0.316997   \n",
       "1  2.0  2.595757  0.394821  2.084765  0.625890 -1.041012 -0.902011  2.008160   \n",
       "2  2.0  0.444136 -0.011482 -1.701330 -0.050268  0.482801  0.116691 -0.797887   \n",
       "\n",
       "         8         9   ...        31        32        33        34        35  \\\n",
       "0 -0.362512  1.534148  ...  1.188112  0.811818 -0.064487 -0.116343 -0.088808   \n",
       "1 -0.928877 -0.976840  ... -1.465534 -1.805827  0.855243  0.769473 -0.466694   \n",
       "2 -1.536126 -1.284072  ...  0.362346 -1.047446 -0.922007 -0.557424  0.461967   \n",
       "\n",
       "         36        37        38        39        40  \n",
       "0  0.095551 -0.181911 -0.297841  0.814936  0.592282  \n",
       "1  0.536960  0.620115 -1.635655 -0.804637 -0.296353  \n",
       "2 -1.569292 -0.663831 -0.605174  0.035432  0.711995  \n",
       "\n",
       "[3 rows x 41 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HOW TO NORMALIZE THE DATA \n",
    "# https://stackoverflow.com/questions/26414913/normalize-columns-of-pandas-data-frame\n",
    "df = personal_large_test.iloc[:,1:personal_large_test.shape[1]]\n",
    "normalized_df=(df-df.mean())/df.std()\n",
    "normalized_df.head(3)\n",
    "personal_large_test_normalized1 = pd.concat([personal_large_test.iloc[:,0:1], normalized_df], axis=1) # concatenate the data\n",
    "personal_large_test_normalized1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.674000</td>\n",
       "      <td>0.112219</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.423441</td>\n",
       "      <td>0.763150</td>\n",
       "      <td>0.462605</td>\n",
       "      <td>0.530676</td>\n",
       "      <td>0.256526</td>\n",
       "      <td>0.621943</td>\n",
       "      <td>0.398540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.183866</td>\n",
       "      <td>0.420886</td>\n",
       "      <td>0.545353</td>\n",
       "      <td>0.158400</td>\n",
       "      <td>0.648128</td>\n",
       "      <td>0.703750</td>\n",
       "      <td>0.603024</td>\n",
       "      <td>0.334221</td>\n",
       "      <td>0.420564</td>\n",
       "      <td>0.163699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.279323</td>\n",
       "      <td>0.559588</td>\n",
       "      <td>0.616622</td>\n",
       "      <td>0.302603</td>\n",
       "      <td>0.503053</td>\n",
       "      <td>0.524647</td>\n",
       "      <td>0.524036</td>\n",
       "      <td>0.753449</td>\n",
       "      <td>0.912570</td>\n",
       "      <td>0.467654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2         3         4         5         6         7   \\\n",
       "0  1.0  0.674000  0.112219  1.000000  0.423441  0.763150  0.462605  0.530676   \n",
       "1  2.0  0.183866  0.420886  0.545353  0.158400  0.648128  0.703750  0.603024   \n",
       "2  2.0  0.279323  0.559588  0.616622  0.302603  0.503053  0.524647  0.524036   \n",
       "\n",
       "         8         9         10  \n",
       "0  0.256526  0.621943  0.398540  \n",
       "1  0.334221  0.420564  0.163699  \n",
       "2  0.753449  0.912570  0.467654  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HOW TO NORMALIZE THE DATA \n",
    "# https://stackoverflow.com/questions/26414913/normalize-columns-of-pandas-data-frame\n",
    "df = personal_small_test.iloc[:,1:personal_small_test.shape[1]]\n",
    "normalized_df=(df-df.min())/(df.max()-df.min())\n",
    "normalized_df.head(3)\n",
    "personal_small_test_normalized2 = pd.concat([personal_small_test.iloc[:,0:1], normalized_df], axis=1) # concatenate the data\n",
    "personal_small_test_normalized2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.484396</td>\n",
       "      <td>0.217274</td>\n",
       "      <td>0.307348</td>\n",
       "      <td>0.294420</td>\n",
       "      <td>0.357973</td>\n",
       "      <td>0.377701</td>\n",
       "      <td>0.571835</td>\n",
       "      <td>0.428805</td>\n",
       "      <td>0.645941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.626500</td>\n",
       "      <td>0.599686</td>\n",
       "      <td>0.510419</td>\n",
       "      <td>0.502124</td>\n",
       "      <td>0.422535</td>\n",
       "      <td>0.538340</td>\n",
       "      <td>0.526813</td>\n",
       "      <td>0.482640</td>\n",
       "      <td>0.596892</td>\n",
       "      <td>0.523254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.948128</td>\n",
       "      <td>0.577976</td>\n",
       "      <td>0.799478</td>\n",
       "      <td>0.661011</td>\n",
       "      <td>0.279250</td>\n",
       "      <td>0.369782</td>\n",
       "      <td>0.824355</td>\n",
       "      <td>0.341708</td>\n",
       "      <td>0.303714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250701</td>\n",
       "      <td>0.168388</td>\n",
       "      <td>0.651891</td>\n",
       "      <td>0.638225</td>\n",
       "      <td>0.363147</td>\n",
       "      <td>0.607774</td>\n",
       "      <td>0.656281</td>\n",
       "      <td>0.278799</td>\n",
       "      <td>0.349999</td>\n",
       "      <td>0.379020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.614126</td>\n",
       "      <td>0.514868</td>\n",
       "      <td>0.166518</td>\n",
       "      <td>0.557945</td>\n",
       "      <td>0.540144</td>\n",
       "      <td>0.530707</td>\n",
       "      <td>0.405364</td>\n",
       "      <td>0.248324</td>\n",
       "      <td>0.261841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509558</td>\n",
       "      <td>0.293343</td>\n",
       "      <td>0.378517</td>\n",
       "      <td>0.434354</td>\n",
       "      <td>0.509094</td>\n",
       "      <td>0.276460</td>\n",
       "      <td>0.449019</td>\n",
       "      <td>0.435812</td>\n",
       "      <td>0.478062</td>\n",
       "      <td>0.542684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2         3         4         5         6         7   \\\n",
       "0  2.0  0.484396  0.217274  0.307348  0.294420  0.357973  0.377701  0.571835   \n",
       "1  2.0  0.948128  0.577976  0.799478  0.661011  0.279250  0.369782  0.824355   \n",
       "2  2.0  0.614126  0.514868  0.166518  0.557945  0.540144  0.530707  0.405364   \n",
       "\n",
       "         8         9   ...        31        32        33        34        35  \\\n",
       "0  0.428805  0.645941  ...  0.626500  0.599686  0.510419  0.502124  0.422535   \n",
       "1  0.341708  0.303714  ...  0.250701  0.168388  0.651891  0.638225  0.363147   \n",
       "2  0.248324  0.261841  ...  0.509558  0.293343  0.378517  0.434354  0.509094   \n",
       "\n",
       "         36        37        38        39        40  \n",
       "0  0.538340  0.526813  0.482640  0.596892  0.523254  \n",
       "1  0.607774  0.656281  0.278799  0.349999  0.379020  \n",
       "2  0.276460  0.449019  0.435812  0.478062  0.542684  \n",
       "\n",
       "[3 rows x 41 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HOW TO NORMALIZE THE DATA \n",
    "# https://stackoverflow.com/questions/26414913/normalize-columns-of-pandas-data-frame\n",
    "df = personal_large_test.iloc[:,1:personal_large_test.shape[1]]\n",
    "normalized_df=(df-df.min())/(df.max()-df.min())\n",
    "normalized_df.head(3)\n",
    "personal_large_test_normalized2 = pd.concat([personal_large_test.iloc[:,0:1], normalized_df], axis=1) # concatenate the data\n",
    "personal_large_test_normalized2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# euclidean distance fucntion \n",
    "def EuclideanDistance(x,y):\n",
    "    distance = 0 # the distance between two points\n",
    "    for i in range(len(x)): # calculate the distance between two points\n",
    "        # euclidean distance = sqrt[(x0-y0)^2 + (x1-y1)^2 + ... + (xn-yn)^2]\n",
    "        distance += ( x[i]- y[i] )**2 # sum the square of the difference\n",
    "    distance = math.sqrt(distance) # take the square root of the sum\n",
    "    return distance # return the distance\n",
    "\n",
    "# test our function\n",
    "#EuclideanDistance((5,2),(5,7))\n",
    "#EuclideanDistance((5,2),(5,9))\n",
    "#EuclideanDistance((5,2),(7,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plase ignore the following code, it for test purpose\n",
    "def NN_Neighbor(test_data_set,trian_data_sets):\n",
    "    euclidean_distance = [] #  for store list of euclidean distance of training data\n",
    "    neighbor = [] # for store NN neighbor\n",
    "    for trian_data in trian_data_sets: # loop through all the training data\n",
    "        euclidean_distance.append(EuclideanDistance(trian_data[1:len(trian_data)],test_data_set[1:len(test_data_set)])) # calculate the euclidean distance of each training data and testing data\n",
    "        neighbor.append(min(euclidean_distance)) # store the NN neighbor(smallest euclidean distance) of the training data and testing data\n",
    "    index = euclidean_distance.index(min(euclidean_distance)) # store the index of the NN neighbor\n",
    "    #index = Find_NN_Neighbor(test_data_set,trian_data_sets)\n",
    "    predicted_label = trian_data_sets[index][0] # store the label of the NN neighbor\n",
    "    #print(euclidean_distance)\n",
    "    #print(\"The predicted label is \",predicted_label, \"index\", index)\n",
    "    return predicted_label\n",
    "\n",
    "#NN_Neighbor(test_data,sm_f2_list)\n",
    "# [1,0.01,0.02,0.02],\n",
    "trian_sets = [\n",
    "            [2,0.01,0.01,0.03],\n",
    "            [1,0.02,0.03,0.02],\n",
    "            [1,0.03,0.02,0.02],\n",
    "            [2,0.05,0.01,0.05],]\n",
    "NN_Neighbor([1,0.01,0.02,0.02],trian_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please ignore the following code, its for test purpose\n",
    "def Validator(feature_subset, classifier, dataset):\n",
    "    trian_data_sets = [] # for store the training data\n",
    "    feature_subset.insert(0,0) # for the class label columns\n",
    "    trian_data_sets = dataset.iloc[:,feature_subset] # store the training data sets\n",
    "    trian_sets = trian_data_sets.values.tolist() # convert the dataframe to list\n",
    "    correct_count = 0   # for store the correct count of prediction\n",
    "    accuracy = 0 # for store the accuracy\n",
    "    for i in range(len(trian_sets)): # loop through all the training data\n",
    "        leave_one_out = trian_sets[i] # store the leave one out data(test data)\n",
    "        temp_trian_data_sets = copy.deepcopy(trian_sets) # store the training data sets\n",
    "        temp_trian_data_sets.pop(i) # remove the leave one out data from the training data sets\n",
    "        #print(\"leave_one_out\",leave_one_out)\n",
    "        #print(\"temp_trian_data_sets\",temp_trian_data_sets)\n",
    "        predicted = NN_Neighbor(leave_one_out,temp_trian_data_sets) # predict the label of the leave one out data\n",
    "        #print(\"predicted\",predicted)\n",
    "        #print()\n",
    "        if (predicted == leave_one_out[0]):\n",
    "            correct_count += 1\n",
    "    accuracy = correct_count / (i+1)\n",
    "    #print( \"iteration is \",i+1,\"correct count\", correct_count)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validator class\n",
    "class Validator:\n",
    "    def validator(self, feature_subset, classifier, dataset,k):\n",
    "        trian_data_sets = [] # for store the training data\n",
    "        feature_subsets = copy.deepcopy(feature_subset) # for the class label columns\n",
    "        feature_subsets.insert(0,0) # for the class label columns\n",
    "        trian_data_sets = dataset.iloc[:,feature_subsets] # store the training data sets\n",
    "        trian_sets = trian_data_sets.values.tolist() # convert the dataframe to list\n",
    "        correct_count = 0   # for store the correct count of prediction\n",
    "        accuracy = 0 # for store the accuracy\n",
    "        for i in range(len(trian_sets)): # loop through all the training data\n",
    "            leave_one_out = trian_sets[i] # store the leave one out data(test data)\n",
    "            temp_trian_data_sets = copy.deepcopy(trian_sets) # store the training data sets\n",
    "            temp_trian_data_sets.pop(i) # remove the leave one out data from the training data sets\n",
    "            classifier.train(temp_trian_data_sets) # train the classifier\n",
    "            predicted = classifier.test(leave_one_out,k) # predict the label of the leave one out data\n",
    "            if (predicted == leave_one_out[0]): # if the predicted label is the same as the leave one out data label\n",
    "                correct_count += 1 # increase the correct count\n",
    "        accuracy = (correct_count / (i+1)) # calculate the accuracy\n",
    "        #print( \"iteration is \",i+1,\"correct count\", correct_count)\n",
    "        return accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN Neighbor classifier\n",
    "class NN_Neighbor_Classifier:\n",
    "    def __init__(self): # constructor\n",
    "        self.test_data = None\n",
    "        self.train_data = None\n",
    "    \n",
    "    def train(self, train_data): # train the classifier, get the training data\n",
    "        self.train_data = train_data  \n",
    "    def test(self, test_data, k): # test the classifier, get the testing data and predict the label\n",
    "        self.test_data = test_data\n",
    "        euclidean_distance = [] #  for store list of euclidean distance of training data\n",
    "        neighbor = [] # for store NN neighbor\n",
    "        for trian_data in self.train_data: # loop through all the training data\n",
    "            euclidean_distance.append(  [trian_data[0], EuclideanDistance(trian_data[1:len(trian_data)],self.test_data[1:len(self.test_data)]) ]  ) # calculate the euclidean distance of each training data and testing data\n",
    "        #neighbor.append(min(euclidean_distance)) # store the NN neighbor(smallest euclidean distance) of the training data and testing data\n",
    "        #index = euclidean_distance.index(min(euclidean_distance)) # store the index of the NN neighbor\n",
    "        #predicted_label = self.train_data[index][0] # store the label of the NN neighbor\n",
    "        euclidean_distance.sort(key=lambda x: x[1]) # sort the euclidean distance list\n",
    "        for i in range(k):\n",
    "            neighbor.append(euclidean_distance[i]) # store the K-NN neighbor(smallest euclidean distance) of the training data and testing data\n",
    "        label1 = 0.0 # for store the cout of label1 of the K-NN neighbor\n",
    "        label2 = 0.0 # for store the cout of label2 of the K-NN neighbor\n",
    "        for i in range(len(neighbor)): # loop through all the K-NN neighbor\n",
    "            if (neighbor[i][0] == 2.0):    # if the label of the K-NN neighbor is 2\n",
    "                label2 += 1 # increase the count of label2\n",
    "            else: # if the label of the K-NN neighbor is 1\n",
    "                label1 += 1 # increase the count of label1\n",
    "        if (label1 > label2): # if the count of label1 is greater than the count of label2\n",
    "            predicted_label = 1.0 # predict the label as 1\n",
    "        else: # if the count of label1 is less than the count of label2\n",
    "            predicted_label = 2.0 # predict the label as 2\n",
    "        return predicted_label # return the label of the NN neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ForwardSelection(feature_set,dataset,k):\n",
    "    classifier = NN_Neighbor_Classifier() # create a classifier\n",
    "    validator = Validator() # create a validator\n",
    "    q = queue.PriorityQueue() # priority queue\n",
    "    num_feature = len(feature_set)\n",
    "    #res = queue.PriorityQueue()\n",
    "    a = 0 # accuracy\n",
    "    f = [] # for initial feature set\n",
    "    a = validator.validator(f, classifier, dataset,k) # validate the initial feature set, which it is accuracy\n",
    "    root = Node(f, None, a) # root node\n",
    "    #print(root.get_current_node())\n",
    "    q.put(root) #   put the root node into the queue\n",
    "    print(\"Using no features and \\\"random\\\" evalution, I get an accuracy of \", a*100,\"%\\n\") # print the accuracy\n",
    "    print(\"Beginning search (Forward Selection):\") # print the beginning of the search\n",
    "    child_node = [] # this is for the children of the current node\n",
    "    next_expend = [] # this is for the next node to be expanded\n",
    "    index = 0 # this is for the index of the current node\n",
    "    max_feature = root # assume our root node as  the max feature\n",
    "    while not q.empty(): \n",
    "        next_expend = q.get()\n",
    "        #res.put(next_expend)\n",
    "        if (next_expend.get_accuracy() > max_feature.get_accuracy()): # if the accuracy of the current node is greater than the max accuracy\n",
    "            max_feature = next_expend # update the max feature\n",
    "        child_node = [] # list of child node\n",
    "        feature_list = [] # list of current features\n",
    "        for feature in (feature_set): # for all the current features\n",
    "            p_temp = copy.deepcopy(next_expend.get_current_node()) # copy the current node\n",
    "            if (feature not in p_temp): # if the current feature is not in the current node\n",
    "                p_temp.insert(0, feature) # add the new feature to the current node(feature sets)\n",
    "                feature_list.append(p_temp)# add the current features to the list of features and avoid to use duplicated features\n",
    "        for f_temp in feature_list: # for all the features in the list of features\n",
    "            a = validator.validator(f_temp, classifier, dataset,k) # validate the feature set, which it is return accuracy\n",
    "            child = Node(f_temp,next_expend,a) # create a child node\n",
    "            child_node.append(child) #  add the child node to the list of child node\n",
    "            print(\"Using features(s)\",child.get_current_node(),\"accuracy is \", child.get_accuracy()*100,\"%\")  # print the accuracy\n",
    "        next_expend = child_node[0] # set the next node to be expanded to be the first child node\n",
    "        num_drop_accuracy = 0 # number of accuracy drop\n",
    "        for i in child_node: # for all the child nodes\n",
    "            if i.get_accuracy() > next_expend.get_accuracy(): # if the child accuracy of the current node is greater than the current expend node accuracy\n",
    "                next_expend = i # update the next expend node\n",
    "            if (i.get_accuracy() < max_feature.get_accuracy()):\n",
    "                num_drop_accuracy += 1\n",
    "        if (num_drop_accuracy == len(child_node) and index !=0):\n",
    "            print(\"Warning: the accuracy is not increasing!!!\") # print the warning\n",
    "            print(\"Finished search!! \", \"The best features are \", max_feature.get_current_node(), \" which has accuracy \", max_feature.get_accuracy()*100,\"%\\n\\n\") # print the best accuracy and the best features\n",
    "            break\n",
    "        q.put(next_expend) # put the next expend node into the queue\n",
    "        index+=1 # update the index\n",
    "        if (index >= num_feature): # if the index is greater than the number of features end the search\n",
    "            #if  (next_expend.get_accuracy() < max_feature.get_accuracy()): # if the accuracy of the current node is less than the max accuracy\n",
    "            #    print(\"Warning: the accuracy is not increasing!!!\") # print the warning\n",
    "            #    print(\"Finished search!! \", \"The best features are \", max_feature.get_current_node(), \" which has accuracy \", max_feature.get_accuracy()*100,\"%\\n\\n\") # print the best accuracy and the best features\n",
    "            #else: # if the accuracy of the current node is greater than the max accuracy, then no warning\n",
    "            print(\"Finished search!! \", \"The best features are \", next_expend.get_current_node(), \" which has accuracy \", next_expend.get_accuracy()*100,\"%\\n\\n\") # print the best accuracy and the best features\n",
    "            break # break the loop stop the search\n",
    "        print(\"\\nFeature set \", next_expend.get_current_node(), \" was best, accuracy is \", next_expend.get_accuracy()*100,\"%\") # print the current best feature set and the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BackwardElimination(feature_sets, dataset,k):\n",
    "    classifier = NN_Neighbor_Classifier() # create a classifier\n",
    "    validator = Validator() # create a validator\n",
    "    num_feature = len(feature_sets) # number of features\n",
    "    q = queue.PriorityQueue() # queue for the nodes\n",
    "    #res = queue.PriorityQueue()\n",
    "    f = [] # store the initil feature, in this case would be all the features\n",
    "    f = copy.deepcopy(feature_sets) # copy the feature\n",
    "    a = validator.validator(f, classifier, dataset,k) # accuracy\n",
    "    root = Node(f, None, a) # root node\n",
    "    #print(root.get_current_node())\n",
    "    q.put(root) # put the root node into the queue\n",
    "    print(\"Using all feature(s)\", root.get_current_node(), \", I get an accuracy of \", a*100,\"%\\n\") # print the accuracy\n",
    "    print(\"Beginning search (Backward Elimination):\") # print the search\n",
    "    child_node = [] # this is for the children of the current node\n",
    "    next_expend = [] # this is for the next node to be expanded\n",
    "    index = 0 # index for the loop to stop the search\n",
    "    max_feature = root # asume the root is the currrent max feature\n",
    "    current_num_feature = num_feature # current number of features\n",
    "    while not q.empty(): # loop until the queue is empty\n",
    "        next_expend = q.get() # get the next node to be expanded\n",
    "        #res.put(next_expend)\n",
    "        if (next_expend.get_accuracy() >= max_feature.get_accuracy()): # if the accuracy is better than the current max feature\n",
    "            max_feature = next_expend # update the max feature\n",
    "        child_node = [] # list of child node\n",
    "        feature_list = [] # list of current features\n",
    "        for i in range(current_num_feature): # loop through all the current features\n",
    "            p_temp = copy.deepcopy(next_expend.get_current_node()) # copy the current node\n",
    "            p_temp.pop(i) # remove the one of the current feature\n",
    "            feature_list.append(p_temp) # add the current features to the list of features and avoid to use duplicated features\n",
    "        for f_temp in feature_list: # loop through all the features\n",
    "            a = validator.validator(f_temp, classifier, dataset,k) # accuracy\n",
    "            child = Node(f_temp,next_expend,a) # child node\n",
    "            child_node.append(child) # add the child node to the list of child node\n",
    "            if (len(feature_list) == 1): # if there is only one feature left\n",
    "                print(\"Using \",child.get_current_node(),\"no features and \\\"random\\\" evalution, I get an accuracy of \", child.get_accuracy()*100,\"%\\n\") # print the accuracy\n",
    "            else: # if there are more than one feature left\n",
    "                print(\"Using features(s)\",child.get_current_node(),\"accuracy is \", child.get_accuracy()*100,\"%\")  # print the accuracy\n",
    "        current_num_feature-=1 # update the number of features for next expend\n",
    "        num_drop_accuracy = 0 # number of accuracy drop\n",
    "        #print(\"Child node length: \",len(child_node))\n",
    "        if (len(child_node) >= 1): # if there is at least one child node\n",
    "            next_expend = child_node[0] # set the next node to be expanded to the first child node\n",
    "            for i in child_node:  # loop through all the child node\n",
    "                if i.get_accuracy() > next_expend.get_accuracy(): # if the child accuracy is better than the current node's accurcy\n",
    "                    next_expend = i # update the next node to be expanded\n",
    "                if (i.get_accuracy() < max_feature.get_accuracy()):\n",
    "                    num_drop_accuracy += 1\n",
    "        if (num_drop_accuracy == len(child_node)):\n",
    "            print(\"Warning: the accuracy is not increasing!!!\") # print warning\n",
    "            print(\"Finished search!! \", \"The best features are \", max_feature.get_current_node(), \" which has accuracy \", max_feature.get_accuracy()*100,\"%\\n\\n\")\n",
    "            break\n",
    "        q.put(next_expend) # put the next node to be expanded into the queue\n",
    "        index+=1 # update the index for the loop control variable\n",
    "        if (index >= num_feature): # if the index is larger than the number of features\n",
    "            #if  (next_expend.get_accuracy() < max_feature.get_accuracy()): # if the accuracy is not increasing\n",
    "            #    print(\"Warning: the accuracy is not increasing!!!\") # print warning\n",
    "            #    print(\"Finished search!! \", \"The best features are \", max_feature.get_current_node(), \" which has accuracy \", max_feature.get_accuracy()*100,\"%\\n\\n\")\n",
    "            #else: # if the accuracy is increasing\n",
    "                # print normal\n",
    "            print(\"Finished search!! \", \"The best features are \", next_expend.get_current_node(), \" which has accuracy \", next_expend.get_accuracy()*100,\"%\\n\\n\")\n",
    "            break # break the loop\n",
    "        print(\"\\nFeature set \", next_expend.get_current_node(), \" was best, accuracy is \", next_expend.get_accuracy()*100,\"%\") # print the best current feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bidirection Elimination\n",
    "# https://stats.stackexchange.com/questions/421361/how-exactly-does-bidirectional-stepwise-elimination-works\n",
    "def BidirectionalElimination(feature_sets, dataset,k):\n",
    "    classifier = NN_Neighbor_Classifier() # create a classifier\n",
    "    validator = Validator() # create a validator\n",
    "    q = queue.PriorityQueue() # priority queue\n",
    "    num_feature = len(feature_sets)\n",
    "    #res = queue.PriorityQueue()\n",
    "    a = 0 # accuracy\n",
    "    f = [] # for initial feature set\n",
    "    a = validator.validator(f, classifier, dataset,k) # validate the initial feature set, which it is accuracy\n",
    "    root = Node(f, None, a) # root node\n",
    "    #print(root.get_current_node())\n",
    "    q.put(root) #   put the root node into the queue\n",
    "    print(\"Using no features and \\\"random\\\" evalution, I get an accuracy of \", a*100,\"%\\n\") # print the accuracy\n",
    "    print(\"Beginning search(Bidirection Elimination)\") # print the beginning of the search\n",
    "    child_node = [] # this is for the children of the current node\n",
    "    next_expend = [] # this is for the next node to be expanded\n",
    "    index = 0 # this is for the index of the current node\n",
    "    eliminate_feature = [] # this is for the features to be eliminated\n",
    "    max_feature = root # assume our root node as  the max feature\n",
    "    while not q.empty(): \n",
    "        next_expend = q.get()\n",
    "        #res.put(next_expend)\n",
    "        if (next_expend.get_accuracy() > max_feature.get_accuracy()): # if the accuracy of the current node is greater than the max accuracy\n",
    "            max_feature = next_expend # update the max feature\n",
    "        child_node = [] # list of child node\n",
    "        feature_list = [] # list of current features\n",
    "        for feature in (feature_sets): # for all the current features\n",
    "            p_temp = copy.deepcopy(next_expend.get_current_node()) # copy the current node\n",
    "            if (feature not in p_temp and feature not in eliminate_feature): # if the current feature is not in the current node\n",
    "                p_temp.insert(0, feature) # add the new feature to the current node(feature sets)\n",
    "                feature_list.append(p_temp)# add the current features to the list of features and avoid to use duplicated features\n",
    "        eliminate_num = 0 # number of features to be eliminated\n",
    "        for f_temp in feature_list: # for all the features in the list of features\n",
    "            a = validator.validator(f_temp, classifier, dataset,k) # validate the feature set, which it is return accuracy\n",
    "            child = Node(f_temp,next_expend,a) # create a child node\n",
    "            print(\"Using features(s)\",child.get_current_node(),\"accuracy is \", child.get_accuracy()*100,\"%\")  # print the accuracy\n",
    "            if (child.get_accuracy() < next_expend.get_accuracy() and index !=0): # if the child accuracy is greater than the current node's accuracy\n",
    "                print(\"Eliminated this feature! Since this feautre(s) [\",child.get_current_node()[0],\"] had create the accuracy \", child.get_accuracy()*100, \"% is lower than previous best features accuracy \", next_expend.get_accuracy()*100,\"%\")\n",
    "                eliminate_num+=1 # update the number of features to be eliminated\n",
    "                eliminate_feature.append(child.get_current_node()[0]) # add the feature to the list of features to be eliminated\n",
    "            else:\n",
    "                child_node.append(child) #  add the child node to the list of child node\n",
    "        if (child_node != []): # if there is at least one child node\n",
    "            next_expend = child_node[0] # set the next node to be expanded to be the first child node\n",
    "            current_smallest_accuracy = next_expend # set the smallest accuracy to be the first child node's accuracy\n",
    "            for i in child_node: # for all the child nodes\n",
    "                if i.get_accuracy() > next_expend.get_accuracy(): # if the child accuracy of the current node is greater than the current expend node accuracy\n",
    "                    next_expend = i # update the next expend node\n",
    "                #if i.get_accuracy() < current_smallest_accuracy.get_accuracy():\n",
    "                #    current_smallest_accuracy = i\n",
    "        #print(\"Eliminated this feature! Since this feautre(s) [\",current_smallest_accuracy.get_current_node()[0],\"] had create the lowest accuracy \", current_smallest_accuracy.get_accuracy()*100, \"%. \\n\")\n",
    "        #eliminate_feature.append(current_smallest_accuracy.get_current_node()[0]) # add the feature to be eliminated to the list of features to be eliminated\n",
    "        q.put(next_expend) # put the next expend node into the queue\n",
    "        print(\"Number of features to be eliminated: \", eliminate_num) # print the number of features to be eliminated\n",
    "        index+=1 # update the index of the current node\n",
    "        index+=eliminate_num # update the index of the current node\n",
    "        #print(\"index: \", index)\n",
    "        #print(\"number of features: \", num_feature)\n",
    "        if (index >= num_feature): # if the index is greater than the number of features\n",
    "            if  (next_expend.get_accuracy() < max_feature.get_accuracy()): # if the accuracy of the current node is less than the max accuracy\n",
    "                print(\"We used and eliminated all features!\\n\") \n",
    "                print(\"Warning: the accuracy is not increasing!!!\") # print the warning\n",
    "                print(\"Finished search!! The best accuracy is \", \"The best features are \", max_feature.get_current_node(), \" which has accuracy \", max_feature.get_accuracy()*100,\"%\\n\\n\") # print the best accuracy and the best features\n",
    "            else: # if the accuracy of the current node is greater than the max accuracy, then no warning\n",
    "                print(\"We used and eliminated all features!\\n\") \n",
    "                print(\"Finished search!! The best accuracy is \", \"The best features are \", next_expend.get_current_node(), \" which has accuracy \", next_expend.get_accuracy()*100,\"%\\n\\n\") # print the best accuracy and the best features\n",
    "            break # break the loop stop the search\n",
    "        print(\"\\nFeature set \", next_expend.get_current_node(), \" was best, accuracy is \", next_expend.get_accuracy()*100,\"%\") # print the current best feature set and the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the small test set is  0.89\n",
      "The accuracy of the large test set is  0.949\n"
     ]
    }
   ],
   "source": [
    "classifier = NN_Neighbor_Classifier()\n",
    "#classifier.train(trian_rows)\n",
    "#classifier.test(test_row)\n",
    "validator = Validator()\n",
    "accuracy1 = validator.validator([3,5,7], classifier, small_test,1)\n",
    "accuracy2 = validator.validator([1,15,27], classifier, large_test,1)\n",
    "print(\"The accuracy of the small test set is \",accuracy1)\n",
    "print(\"The accuracy of the large test set is \",accuracy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this part is for part II\n",
    "def part2():\n",
    "    # how to keep track of time use in the program\n",
    "    # https://www.codegrepper.com/code-examples/python/python+track+time+of+execution\n",
    "    start_time = time.time() # start time\n",
    "    classifier = NN_Neighbor_Classifier()\n",
    "    #classifier.train(trian_rows)\n",
    "    #classifier.test(test_row)\n",
    "    validator = Validator()\n",
    "    #validator.validator([3,5,7], classifier, small_test)\n",
    "    #accuracy = validator.validator([1,15,27], classifier, large_test)\n",
    "    \n",
    "    \n",
    "    print(\"NN Neighbor Classifier and Validator testing!\")\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print(\"Enter 0 for default festure set for small and large dataset\")\n",
    "    print(\"Enter 1 to chose the small dataset\")\n",
    "    print(\"Enter 2 to chose the large dataset\")\n",
    "    data_choice = input(\"Please chose your dataset:\")\n",
    "    print(\"---- %s seconds ----\" % (time.time() - start_time))\n",
    "    feature_sets = []\n",
    "    accuracy = 0\n",
    "    if (data_choice == \"1\"):\n",
    "        sets = input(\"Enter your feature subset[1-10]:\")\n",
    "        print(\"---- %s seconds ----\" % (time.time() - start_time))\n",
    "        feature_sets = [int(i) for i in sets.split()]\n",
    "        accuracy = validator.validator(feature_sets, classifier, small_test,1)\n",
    "        print(\"The small dataset with the feautre subset\", feature_sets, \"We have the accuracy is \", accuracy*100, \"%\")\n",
    "        print(\"---- %s seconds ----\" % (time.time() - start_time))\n",
    "    elif (data_choice == \"2\"):\n",
    "        sets = input(\"Enter your feature subset[1-40]:\")\n",
    "        print(\"---- %s seconds ----\" % (time.time() - start_time))\n",
    "        feature_sets = [int(i) for i in sets.split()]\n",
    "        accuracy = validator.validator(feature_sets, classifier, large_test,1)\n",
    "        print(\"The large dataset with the feautre subset\", feature_sets, \"We have the accuracy is \", accuracy*100, \"%\")\n",
    "        print(\"---- %s seconds ----\" % (time.time() - start_time))\n",
    "    elif(data_choice == \"0\"):\n",
    "        accuracy1 =validator.validator([3,5,7], classifier, small_test,1)\n",
    "        print(\"The small dataset with the feautre subset\", [3,5,7], \"We have the accuracy is \", accuracy1*100, \"%\")\n",
    "        print(\"---- %s seconds ----\" % (time.time() - start_time))\n",
    "        accuracy2 = validator.validator([1,15,27], classifier, large_test,1)\n",
    "        print(\"The large dataset with the feautre subset\", [1,15,27], \"We have the accuracy is \", accuracy2*100, \"%\")\n",
    "        print(\"---- %s seconds ----\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part3():\n",
    "    start_time = time.time() # start time\n",
    "    print(\"Welcome to Jianeng Yang Feature Selection Algorithm\")\n",
    "    print(\"Enter 1 to chose the small dataset\")\n",
    "    print(\"Enter 2 to chose the large dataset\")\n",
    "    data_choice = input(\"Please chose your dataset:\")\n",
    "    print(\"---- %s seconds ----\" % (time.time() - start_time))\n",
    "    print(\"Chose type of the algorithm\")\n",
    "    print(\"Enter 1 for Forward Selection\")\n",
    "    print(\"Enter 2 for Backward Elimination\")\n",
    "    print(\"Enter 3 for Jianeng Yang(Bidirection Elimination)'s Special Algorithm.\")\n",
    "    type_alg = input(\"Enter your choice:\")\n",
    "    print(\"---- %s seconds ----\" % (time.time() - start_time))\n",
    "    print(\"Enter 1 to chose all features\")\n",
    "    print(\"Enter 2 to input your subset of features\")\n",
    "    input_feature = input(\"Enter your choice:\")\n",
    "    print(\"Enter your number of neighbors(k-nn):\")\n",
    "    input_k = int(input(\"Enter your k-nn  value:\"))\n",
    "    feature_sets = []\n",
    "    if (data_choice == \"1\"):\n",
    "        print(\"You chose the small dataset, this dataset has 10 features, with \", len(personal_small_test), \" instances. And k-nn is \", input_k)\n",
    "        if (input_feature == \"2\"):\n",
    "            sets = input(\"Enter your feature subset[1-10]:\")\n",
    "            feature_sets = [int(i) for i in sets.split()]\n",
    "        else:\n",
    "            feature_sets = [1,2,3,4,5,6,7,8,9,10]\n",
    "        print(\"---- %s seconds ----\" % (time.time() - start_time))\n",
    "        if (type_alg == \"1\"):\n",
    "            ForwardSelection(feature_sets, personal_small_test,input_k)\n",
    "            print(\"---- %s seconds ----\" % (time.time() - start_time))\n",
    "        elif (type_alg == \"2\"):\n",
    "            BackwardElimination(feature_sets, personal_small_test,input_k)\n",
    "            print(\"---- %s seconds ----\" % (time.time() - start_time))\n",
    "        elif (type_alg == \"3\"):\n",
    "            #Bertie(feature_sets, small_test,1)\n",
    "            BidirectionalElimination(feature_sets, personal_small_test,input_k)\n",
    "            print(\"---- %s seconds ----\" % (time.time() - start_time))\n",
    "    elif(data_choice == \"2\"):\n",
    "        print(\"You chose the large dataset, this dataset has 40 features, with \", len(personal_large_test), \" instances.\")\n",
    "        if (input_feature == \"2\"):\n",
    "            sets = input(\"Enter your feature subset[1-40]:\")\n",
    "            feature_sets = [int(i) for i in sets.split()]\n",
    "        else:\n",
    "            feature_sets = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40]\n",
    "        print(\"---- %s seconds ----\" % (time.time() - start_time))\n",
    "        if (type_alg == \"1\"):\n",
    "            ForwardSelection(feature_sets, personal_large_test,input_k)\n",
    "            print(\"---- %s seconds ----\" % (time.time() - start_time))\n",
    "        elif (type_alg == \"2\"):\n",
    "            BackwardElimination(feature_sets, personal_large_test,input_k)\n",
    "            print(\"---- %s seconds ----\" % (time.time() - start_time))\n",
    "        elif (type_alg == \"3\"):\n",
    "            #Bertie(feature_sets, large_test,1)\n",
    "            BidirectionalElimination(feature_sets, personal_large_test,input_k)\n",
    "            print(\"---- %s seconds ----\" % (time.time() - start_time))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    #part2()\n",
    "    part3()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Jianeng Yang Feature Selection Algorithm\n",
      "Enter 1 to chose the small dataset\n",
      "Enter 2 to chose the large dataset\n",
      "---- 1.9872992038726807 seconds ----\n",
      "Chose type of the algorithm\n",
      "Enter 1 for Forward Selection\n",
      "Enter 2 for Backward Elimination\n",
      "Enter 3 for Jianeng Yang(Bidirection Elimination)'s Special Algorithm.\n",
      "---- 3.2645673751831055 seconds ----\n",
      "Enter 1 to chose all features\n",
      "Enter 2 to input your subset of features\n",
      "Enter your number of neighbors(k-nn):\n",
      "You chose the small dataset, this dataset has 10 features, with  100  instances. And k-nn is  1\n",
      "---- 4.270010232925415 seconds ----\n",
      "Using no features and \"random\" evalution, I get an accuracy of  18.0 %\n",
      "\n",
      "Beginning search(Bidirection Elimination)\n",
      "Using features(s) [1] accuracy is  70.0 %\n",
      "Using features(s) [2] accuracy is  65.0 %\n",
      "Using features(s) [3] accuracy is  70.0 %\n",
      "Using features(s) [4] accuracy is  78.0 %\n",
      "Using features(s) [5] accuracy is  69.0 %\n",
      "Using features(s) [6] accuracy is  69.0 %\n",
      "Using features(s) [7] accuracy is  64.0 %\n",
      "Using features(s) [8] accuracy is  68.0 %\n",
      "Using features(s) [9] accuracy is  80.0 %\n",
      "Using features(s) [10] accuracy is  66.0 %\n",
      "Number of features to be eliminated:  0\n",
      "\n",
      "Feature set  [9]  was best, accuracy is  80.0 %\n",
      "Using features(s) [1, 9] accuracy is  77.0 %\n",
      "Eliminated this feature! Since this feautre(s) [ 1 ] had create the accuracy  77.0 % is lower than previous best features accuracy  80.0 %\n",
      "Using features(s) [2, 9] accuracy is  80.0 %\n",
      "Using features(s) [3, 9] accuracy is  82.0 %\n",
      "Using features(s) [4, 9] accuracy is  93.0 %\n",
      "Using features(s) [5, 9] accuracy is  81.0 %\n",
      "Using features(s) [6, 9] accuracy is  80.0 %\n",
      "Using features(s) [7, 9] accuracy is  81.0 %\n",
      "Using features(s) [8, 9] accuracy is  79.0 %\n",
      "Eliminated this feature! Since this feautre(s) [ 8 ] had create the accuracy  79.0 % is lower than previous best features accuracy  80.0 %\n",
      "Using features(s) [10, 9] accuracy is  79.0 %\n",
      "Eliminated this feature! Since this feautre(s) [ 10 ] had create the accuracy  79.0 % is lower than previous best features accuracy  80.0 %\n",
      "Number of features to be eliminated:  3\n",
      "\n",
      "Feature set  [4, 9]  was best, accuracy is  93.0 %\n",
      "Using features(s) [2, 4, 9] accuracy is  89.0 %\n",
      "Eliminated this feature! Since this feautre(s) [ 2 ] had create the accuracy  89.0 % is lower than previous best features accuracy  93.0 %\n",
      "Using features(s) [3, 4, 9] accuracy is  81.0 %\n",
      "Eliminated this feature! Since this feautre(s) [ 3 ] had create the accuracy  81.0 % is lower than previous best features accuracy  93.0 %\n",
      "Using features(s) [5, 4, 9] accuracy is  82.0 %\n",
      "Eliminated this feature! Since this feautre(s) [ 5 ] had create the accuracy  82.0 % is lower than previous best features accuracy  93.0 %\n",
      "Using features(s) [6, 4, 9] accuracy is  85.0 %\n",
      "Eliminated this feature! Since this feautre(s) [ 6 ] had create the accuracy  85.0 % is lower than previous best features accuracy  93.0 %\n",
      "Using features(s) [7, 4, 9] accuracy is  92.0 %\n",
      "Eliminated this feature! Since this feautre(s) [ 7 ] had create the accuracy  92.0 % is lower than previous best features accuracy  93.0 %\n",
      "Number of features to be eliminated:  5\n",
      "We used and eliminated all features!\n",
      "\n",
      "Finished search!! The best accuracy is  The best features are  [4, 9]  which has accuracy  93.0 %\n",
      "\n",
      "\n",
      "---- 4.817439794540405 seconds ----\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "   main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "### how to keep track of time in python\n",
    "https://www.codegrepper.com/code-examples/python/python+track+time+of+execution\n",
    "### HOW TO NORMALIZE THE DATA \n",
    "https://stackoverflow.com/questions/26414913/normalize-columns-of-pandas-data-frame\n",
    "### Bidirection Elimination\n",
    "https://stats.stackexchange.com/questions/421361/how-exactly-does-bidirectional-stepwise-elimination-works\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "91f765b036545ff613693ff947a77ddd06d0eda93b17a27fa69487033e2af99e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
